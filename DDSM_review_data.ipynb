{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom=pd.read_csv('Dataset/DDSM/csv/dicom_info.csv')\n",
    "\n",
    "dicom=dicom[dicom.SeriesDescription=='cropped images']\n",
    "dicom=dicom.reset_index(drop=True)\n",
    "dicom['PatientID_simplified']=dicom['PatientID'].apply(lambda x:'_'.join(x.split('_')[1:3]))\n",
    "dicom['lr_simplified']=dicom['PatientID'].apply(lambda x:x.split('_')[-3])\n",
    "dicom=dicom.drop_duplicates(subset=['lr_simplified','PatientID_simplified']).reset_index(drop=True)\n",
    "addresses=np.array(dicom['image_path'].apply(lambda x:x.replace(\"CBIS-\",'Dataset/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_address):\n",
    "    im=cv2.imread(image_address)\n",
    "    im=cv2.resize(im,(256,256))\n",
    "    return im\n",
    "\n",
    "def load_data_pid_lr(pid,lr):\n",
    "    temp=dicom[(dicom['PatientID_simplified']==pid) & (dicom['lr_simplified']==lr)]\n",
    "    return load_image(temp.iloc[0]['image_path'].replace(\"CBIS-\",'Dataset/'))\n",
    "def load_data(df):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in tqdm.tqdm(range(df.shape[0])):\n",
    "        x.append(load_data_pid_lr(df.iloc[i]['patient_id'],df.iloc[i]['left or right breast']))\n",
    "        y.append(df.iloc[i]['pathology'])\n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images=[]\n",
    "# for item in tqdm.tqdm(addresses):\n",
    "#     images.append(load_image(item))\n",
    "# images=np.array(images)\n",
    "# cv2.imshow('test',images[56])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict={'BENIGN_WITHOUT_CALLBACK':0.0001,'BENIGN':0.0001,'MALIGNANT':0.9999}\n",
    "calc_train=pd.read_csv('Dataset/DDSM/csv/calc_case_description_train_set.csv')\n",
    "calc_train=calc_train.drop_duplicates(subset=['patient_id','left or right breast'])\n",
    "calc_train['pathology']=calc_train['pathology'].replace(replace_dict)\n",
    "\n",
    "\n",
    "calc_test=pd.read_csv('Dataset/DDSM/csv/calc_case_description_test_set.csv')\n",
    "calc_test=calc_test.drop_duplicates(subset=['patient_id','left or right breast'])\n",
    "calc_test['pathology']=calc_test['pathology'].replace(replace_dict)\n",
    "\n",
    "mass_train=pd.read_csv('Dataset/DDSM/csv/mass_case_description_train_set.csv')\n",
    "mass_train=mass_train.drop_duplicates(subset=['patient_id','left or right breast'])\n",
    "mass_train['pathology']=mass_train['pathology'].replace(replace_dict)\n",
    "\n",
    "\n",
    "mass_test=pd.read_csv('Dataset/DDSM/csv/mass_case_description_test_set.csv')\n",
    "mass_test=mass_test.drop_duplicates(subset=['patient_id','left or right breast'])\n",
    "mass_test['pathology']=mass_test['pathology'].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/662 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 662/662 [00:02<00:00, 263.06it/s]\n",
      "100%|██████████| 161/161 [00:00<00:00, 311.95it/s]\n",
      "100%|██████████| 722/722 [00:01<00:00, 449.89it/s]\n",
      "100%|██████████| 210/210 [00:00<00:00, 416.57it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train=[]\n",
    "X_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "x,y=load_data(calc_train)\n",
    "X_train.append(x)\n",
    "y_train.append(y)\n",
    "x,y=load_data(calc_test)\n",
    "X_test.append(x)\n",
    "y_test.append(y)\n",
    "\n",
    "x,y=load_data(mass_train)\n",
    "X_train.append(x)\n",
    "y_train.append(y)\n",
    "x,y=load_data(mass_test)\n",
    "X_test.append(x)\n",
    "y_test.append(y)\n",
    "X_train=np.concatenate(X_train,axis=0)\n",
    "y_train=np.concatenate(y_train,axis=0)\n",
    "X_test=np.concatenate(X_test,axis=0)\n",
    "y_test=np.concatenate(y_test,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P_dataset(Dataset):\n",
    "    def __init__(self, X,y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "            x=self.X[item]\n",
    "            y=self.y[item]\n",
    "            return torch.tensor(np.array(x)+1/255,dtype=torch.float32),torch.tensor(np.array(y),dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=P_dataset(X_train,y_train)\n",
    "data_test=P_dataset(X_test,y_test)\n",
    "train_loader=DataLoader(data_train,batch_size=16,shuffle=True)\n",
    "test_loader=DataLoader(data_test,batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.cnn1=nn.Conv2d(3,3,5)\n",
    "        self.bn1=nn.BatchNorm2d(3)\n",
    "        self.mp1=nn.MaxPool2d(4,stride=4)\n",
    "        self.cnn2=nn.Conv2d(3,6,4)\n",
    "        self.bn2=nn.BatchNorm2d(6)\n",
    "        self.mp2=nn.MaxPool2d(4,stride=4)\n",
    "        self.cnn3=nn.Conv2d(6,12,4)\n",
    "        self.bn3=nn.BatchNorm2d(12)\n",
    "        self.mp3=nn.MaxPool2d(4,stride=4)\n",
    "        # self.cnn4=nn.Conv2d(12,24,3)\n",
    "        # self.mp4=nn.MaxPool2d(2,stride=2)\n",
    "        # self.cnn5=nn.Conv2d(24,48,3)\n",
    "        # self.mp5=nn.MaxPool2d(2,stride=2)\n",
    "        self.final=nn.Linear(12*3*3,1)\n",
    "    def forward(self, x):\n",
    "        x=torch.permute(x,(0,3,1,2))\n",
    "        b=x.size(0)\n",
    "        x=F.relu(self.bn1(self.cnn1(x)))\n",
    "        x=self.mp1(x)\n",
    "        x=F.relu(self.bn2(self.cnn2(x)))\n",
    "        x=self.mp2(x)\n",
    "        x=F.relu(self.bn3(self.cnn3(x)))\n",
    "        x=self.mp3(x)\n",
    "        # x=self.cnn4(x)\n",
    "        # x=self.mp4(x)\n",
    "        # x=self.cnn5(x)\n",
    "        # x=self.mp5(x)\n",
    "        x=x.reshape(b,-1)\n",
    "        x=F.sigmoid(self.final(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCELOSS=nn.BCELoss()\n",
    "def loss_fn(y,y_hat):\n",
    "    y_hat=y_hat.view(-1,)\n",
    "    loss=BCELOSS(y,y_hat)\n",
    "    acc=torch.sum((y>0.5)==(y_hat>0.5))/y.shape[0]\n",
    "    return loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: train_loss: 4.295618190162483, test_loss: 4.6661011897958815, train_acc: 0.5387930870056152, test_acc: 0.4895833432674408,\n",
      "EPOCH 1: train_loss: 3.975886076346211, test_loss: 3.8464912387231984, train_acc: 0.5696839094161987, test_acc: 0.5911458134651184,\n",
      "EPOCH 2: train_loss: 4.000957794573115, test_loss: 3.790257347126802, train_acc: 0.5639367699623108, test_acc: 0.5963541865348816,\n",
      "EPOCH 3: train_loss: 3.9868066324584785, test_loss: 3.7687084674835205, train_acc: 0.5682471394538879, test_acc: 0.592881977558136,\n",
      "EPOCH 4: train_loss: 3.932878949176306, test_loss: 3.76523091395696, train_acc: 0.5732758641242981, test_acc: 0.5902777910232544,\n",
      "EPOCH 5: train_loss: 3.8604857126871743, test_loss: 3.7514585306247077, train_acc: 0.5833333134651184, test_acc: 0.5902777910232544,\n",
      "EPOCH 6: train_loss: 3.910719082273286, test_loss: 3.9738141049941382, train_acc: 0.5761494040489197, test_acc: 0.569444477558136,\n",
      "EPOCH 7: train_loss: 3.780059697984279, test_loss: 4.552475370022269, train_acc: 0.5933908224105835, test_acc: 0.5026041865348816,\n",
      "EPOCH 8: train_loss: 3.8116070210248574, test_loss: 3.6294805655876794, train_acc: 0.5869252681732178, test_acc: 0.6111111044883728,\n",
      "EPOCH 9: train_loss: 3.885403319336902, test_loss: 3.9644127587477365, train_acc: 0.5775862336158752, test_acc: 0.561631977558136,\n",
      "EPOCH 10: train_loss: 3.6458284334204665, test_loss: 3.9698997835318246, train_acc: 0.6063218116760254, test_acc: 0.5703125,\n",
      "EPOCH 11: train_loss: 4.137846635675978, test_loss: 3.9408286660909653, train_acc: 0.5502873659133911, test_acc: 0.5729166865348816,\n",
      "EPOCH 12: train_loss: 4.04495684442849, test_loss: 4.1319761623938875, train_acc: 0.5617815852165222, test_acc: 0.5520833134651184,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Jobs\\Mahyarlab\\Health\\Code\\DDSM_review_data.ipynb Cell 13\u001b[0m line \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m y_hat \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss,acc\u001b[39m=\u001b[39mloss_fn(y,y_hat)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m train_loss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32md:\\Programs\\Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mf:\\Jobs\\Mahyarlab\\Health\\Code\\DDSM_review_data.ipynb Cell 13\u001b[0m line \u001b[0;36mConvModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpermute(x,(\u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m b\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m x\u001b[39m=\u001b[39mF\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn1(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmp1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Jobs/Mahyarlab/Health/Code/DDSM_review_data.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m x\u001b[39m=\u001b[39mF\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcnn2(x)))\n",
      "File \u001b[1;32md:\\Programs\\Python\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programs\\Python\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    180\u001b[0m     bn_training,\n\u001b[0;32m    181\u001b[0m     exponential_average_factor,\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    183\u001b[0m )\n",
      "File \u001b[1;32md:\\Programs\\Python\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[0;32m   2452\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device='cpu'\n",
    "model=ConvModel()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss=0\n",
    "    train_acc=0\n",
    "    test_loss=0\n",
    "    test_acc=0\n",
    "    train_len=0\n",
    "    test_len=0\n",
    "    model.train()\n",
    "    for x,y in train_loader:\n",
    "        train_len+=x.shape[0]\n",
    "        x = x.to(device) # GPU\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        loss,acc=loss_fn(y,y_hat)\n",
    "        train_loss+=loss.detach().numpy()\n",
    "        train_acc+=acc\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "    model.eval()    \n",
    "    for x,y in test_loader:\n",
    "        test_len+=x.shape[0]\n",
    "        x = x.to(device) # GPU\n",
    "        y = y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss,acc=loss_fn(y,y_hat)\n",
    "        test_loss+=loss.detach().numpy()\n",
    "        test_acc+=acc\n",
    "    train_loss=train_loss/len(train_loader)\n",
    "    train_acc=train_acc/len(train_loader)\n",
    "    test_loss=test_loss/len(test_loader)\n",
    "    test_acc=test_acc/len(test_loader)\n",
    "    print(f\"EPOCH {epoch}: train_loss: {train_loss}, test_loss: {test_loss}, train_acc: {train_acc}, test_acc: {test_acc},\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
